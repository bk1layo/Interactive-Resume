{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Path and Dropping NaN values\n",
    "path = r'C:\\Users\\Christian Layo\\Documents\\VSCODE\\Life Expectancy Data.csv'\n",
    "data = pd.read_csv(path)\n",
    "cleanData = data.dropna()\n",
    "\n",
    "#Variables for Multiple Linear Regression\n",
    "X = cleanData[['Adult Mortality','Alcohol','BMI','HIV/AIDS','thinness  1-19 years','thinness 5-9 years','Income composition of resources','Schooling']]\n",
    "y = cleanData[['Life expectancy']]\n",
    "\n",
    "#train_test_split method for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#creating Linear Regression Model and fitting our Training Data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "#Predict method to predict life expectancy age\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"The Coefficient for the X values are: {coef}\")\n",
    "print(f\"The Intercept is: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Finding MSE and R^2 on Training Data and Testing Data\n",
    "mse_train = mean_squared_error(y_train,y_train_pred)\n",
    "r2_train = r2_score(y_train,y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Mean Squared Error for train: {mse_train}\")\n",
    "print(f\"R Squared for train: {r2_train}\")\n",
    "\n",
    "print(f\"\\nMean Squared Error for test: {mse_test}\")\n",
    "print(f\"R Squared for test: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#Convert to Array so Matplotlib can be compatible with the Data\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train_pred = np.array(y_train_pred)\n",
    "y_test_pred = np.array(y_test_pred)\n",
    "\n",
    "#Scatter plot for both training data and testing data\n",
    "plt.scatter(y_train, y_train_pred, label='Training Data', color='blue', alpha=0.5)\n",
    "plt.scatter(y_test, y_test_pred, label='Testing Data', color='red', alpha=0.5)\n",
    "\n",
    "#Min and Max value for training and testing data\n",
    "min_val = min(y_train.min(), y_test.min(), y_train_pred.min(), y_test_pred.min())\n",
    "max_val = max(y_train.max(), y_test.max(), y_train_pred.max(), y_test_pred.max())\n",
    "\n",
    "#Plotting the regression line\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linewidth=2, label='Regression Line')\n",
    "\n",
    "plt.xlabel('Actual Life Expectancy')\n",
    "plt.ylabel('Predicted Life Expectancy')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Results')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Run the script with memory profiling using subprocess\n",
    "subprocess.run(['mprof', 'run', 'statistics/memory.py'])\n",
    "\n",
    "# List all memory usage data files the output is structured like this: id filename time date\n",
    "files = subprocess.check_output(['mprof', 'list']).decode('utf-8').strip().split('\\n')\n",
    "\n",
    "# Get the most recent memory usage data file (sorted by id)\n",
    "filename = files[-1].split()[1]\n",
    "\n",
    "# Read the memory usage data file\n",
    "output = open(filename, 'rb').read()\n",
    "\n",
    "# Clean up the memory usage data file by running it through mprof clean\n",
    "os.system(f'mprof clean')\n",
    "\n",
    "# Parse the memory data and extract memory usage values and timestamps\n",
    "timestamps = []\n",
    "memory_usages = []\n",
    "first_timestamp = None\n",
    "\n",
    "# Iterate through each line in the memory data\n",
    "for line in output.decode('utf-8').strip().split('\\n'):\n",
    "    # Skip the first line\n",
    "    if line.startswith('CMDLINE'):\n",
    "        continue\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) == 3:\n",
    "        try:\n",
    "            # Make the first timestamp 0\n",
    "            if first_timestamp is None:\n",
    "                first_timestamp = float(parts[2])\n",
    "                \n",
    "            # Calculate the timestamp and memory usage\n",
    "            timestamp = float(parts[2]) - first_timestamp\n",
    "            memory_usage = float(parts[1])\n",
    "            timestamps.append(timestamp)\n",
    "            memory_usages.append(memory_usage)\n",
    "        except ValueError:\n",
    "            pass  # Skip lines that don't have valid data\n",
    "\n",
    "# Create a memory usage plot\n",
    "plt.plot(timestamps, memory_usages)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "plt.title('Memory Usage Over Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the memory usage plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file cpu_usage_measurements.csv for reading\n",
    "with open('cpu_usage_measurements.csv', 'r') as f:\n",
    "    # Skip the first line\n",
    "    f.readline()\n",
    "    # Read all lines from the file into a list\n",
    "    cpuLines = f.readlines()\n",
    "\n",
    "# Open the file time_measurements.csv for reading\n",
    "with open('time_measurements.csv', 'r') as f:\n",
    "    # Skip the first line\n",
    "    f.readline()\n",
    "    # Read all lines from the file into a list\n",
    "    timeLines = f.readlines()\n",
    "\n",
    "# Delete the file time_measurements.csv\n",
    "os.remove('time_measurements.csv')\n",
    "# Delete the file cpu_usage_measurements.csv\n",
    "os.remove('cpu_usage_measurements.csv')\n",
    "\n",
    "# Make it a float\n",
    "cpuLines = [float(line.strip()) for line in cpuLines]\n",
    "\n",
    "timeLines = [float(line.strip()) for line in timeLines]\n",
    "\n",
    "# Show the data on a plot\n",
    "plt.plot(timeLines, cpuLines)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('CPU Usage (%)')\n",
    "plt.title('CPU Usage Over Time')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Path and Dropping NaN values\n",
    "# path = r'C:\\Users\\layoc\\OneDrive\\Documents\\VSCodeLearn\\Life Expectancy Data.csv'\n",
    "# Change path to suit your local environment\n",
    "data = pd.read_csv('LifeExpectancy.csv')\n",
    "cleanData = data.dropna()\n",
    "\n",
    "#Variables for Multiple Linear Regression\n",
    "# or we can use an index to slice\n",
    "X2 = cleanData[['Adult Mortality','infant deaths','Alcohol','percentage expenditure','Hepatitis B','Measles','BMI','under-five deaths','Polio','Total expenditure',\n",
    "               'Diphtheria ','HIV/AIDS','GDP','Population','thinness  1-19 years','thinness 5-9 years','Income composition of resources','Schooling']]\n",
    "y2 = cleanData[['Life expectancy']]\n",
    "\n",
    "#train_test_split method for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2,y2,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Importing DecisionTreeRegressor so we can predict from class labels of data points instead of numerical\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "treeReg = DecisionTreeRegressor(\n",
    "    max_depth=5,              # Set the maximum depth of the tree\n",
    "    min_samples_split=5,      # Set the minimum samples required to split a node\n",
    "    min_samples_leaf=2,       # Set the minimum samples required in a leaf node\n",
    "    max_leaf_nodes=None,      # Limit the maximum number of leaf nodes (optional)\n",
    "    min_impurity_decrease=0.0)\n",
    "\n",
    "treeReg.fit(X_train, y_train)\n",
    "\n",
    "yTreeTest_pred = treeReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE and R squared for test and train data for the DecisionTree\n",
    "mse_treeTest = mean_squared_error(y_test, yTreeTest_pred)\n",
    "r2_treeTest = r2_score(y_test, yTreeTest_pred)\n",
    "\n",
    "print(f\"Decision Tree testing data MSE: {mse_treeTest}\")\n",
    "print(f\"Decision Tree testing R squared: {r2_treeTest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "dotData = export_graphviz(\n",
    "        treeReg,\n",
    "        feature_names= X2.columns,\n",
    "        class_names= y2,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "graphviz.Source(dotData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = treeReg.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importances\n",
    "importance_df = pd.DataFrame({'Feature': X2.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestTreeReg = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth':[3,4,5,6],         # Set the maximum depth of the tree\n",
    "    'max_leaf_nodes':[None,6,7],   # Limit the maximum number of leaf nodes (optional)\n",
    "    'min_samples_split':[2,3,4],   # Set the minimum samples required to split a node\n",
    "    'min_samples_leaf':[1,2,3,4,5] # Set the minimum samples required in a leaf node\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(bestTreeReg, param_grid = param_grid, cv = 5, scoring = 'r2', refit=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters : ', grid_search.best_params_)\n",
    "print('best score : ', round(grid_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestTree = DecisionTreeRegressor(\n",
    "    max_depth=6,                  # Set the maximum depth of the tree\n",
    "    min_samples_split=2,          # Set the minimum samples required to split a node\n",
    "    min_samples_leaf=4,           # Set the minimum samples required in a leaf node\n",
    "    max_leaf_nodes=None,          # Limit the maximum number of leaf nodes (optional)\n",
    "    min_impurity_decrease=0.0)\n",
    "\n",
    "\n",
    "bestTree.fit(X_train, y_train)\n",
    "\n",
    "best_pred = bestTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE and R squared for test and train data for the DecisionTree\n",
    "mse_treeTest = mean_squared_error(y_test, best_pred)\n",
    "r2_treeTest = r2_score(y_test, best_pred)\n",
    "\n",
    "print(f\"Best Decision Tree testing data MSE: {mse_treeTest}\")  # or we can use RMSE\n",
    "print(f\"Best Decision Tree testing R score: {r2_treeTest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(\n",
    "    bestTree,\n",
    "    feature_names = X2.columns,\n",
    "    class_names = y2,\n",
    "    rounded=True\n",
    ")\n",
    "\n",
    "graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = bestTree.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importances\n",
    "importance_df = pd.DataFrame({'Feature': X2.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
